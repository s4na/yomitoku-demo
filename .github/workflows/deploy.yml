name: Deploy to GitHub Pages

on:
  push:
    branches:
      - main
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: ğŸ’¾ Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}-yomitoku-torch
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: ğŸ“¦ Install YomiToku
        run: |
          pip install yomitoku torch

      - name: ğŸ“¥ Export ONNX models
        run: |
          mkdir -p ./models
          python3 << 'EOF'
          import os
          import sys

          print("ğŸ”„ Exporting models for GitHub Pages...")

          # Check YomiToku version
          import yomitoku
          print(f"YomiToku version: {yomitoku.__version__ if hasattr(yomitoku, '__version__') else 'unknown'}")

          success = False

          # Method 1: Try using infer_onnx flag (current API in some versions)
          if not success:
              try:
                  print("\nğŸ“¦ Method 1: Using DocumentAnalyzer with infer_onnx flag...")
                  from yomitoku import DocumentAnalyzer

                  analyzer = DocumentAnalyzer(configs={"device": "cpu", "infer_onnx": True})

                  # Try to access the models and export
                  if hasattr(analyzer, 'text_detector'):
                      print("  Exporting text_detector...")
                      analyzer.text_detector.model_manager.model.export_to_onnx("./models/text_detector.onnx")
                      print("  âœ… text_detector exported")

                  if hasattr(analyzer, 'text_recognizer'):
                      print("  Exporting text_recognizer...")
                      analyzer.text_recognizer.model_manager.model.export_to_onnx("./models/text_recognizer.onnx")
                      print("  âœ… text_recognizer exported")

                  if os.path.exists("./models/text_detector.onnx") and os.path.exists("./models/text_recognizer.onnx"):
                      success = True
                      print("âœ… Method 1 succeeded!")
              except Exception as e:
                  print(f"  âŒ Method 1 failed: {e}")

          # Method 2: Direct module import
          if not success:
              try:
                  print("\nğŸ“¦ Method 2: Direct module import...")
                  from yomitoku.text_detector.v2.text_detector import TextDetector
                  from yomitoku.text_recognizer.text_recognizer import TextRecognizer

                  detector = TextDetector(configs={"device": "cpu"})
                  if hasattr(detector, 'model_manager'):
                      detector.model_manager.model.export_to_onnx("./models/text_detector.onnx")
                  else:
                      detector.model.export_to_onnx("./models/text_detector.onnx")
                  print("  âœ… text_detector exported")

                  recognizer = TextRecognizer(configs={"device": "cpu"})
                  if hasattr(recognizer, 'model_manager'):
                      recognizer.model_manager.model.export_to_onnx("./models/text_recognizer.onnx")
                  else:
                      recognizer.model.export_to_onnx("./models/text_recognizer.onnx")
                  print("  âœ… text_recognizer exported")

                  success = True
                  print("âœ… Method 2 succeeded!")
              except Exception as e:
                  print(f"  âŒ Method 2 failed: {e}")

          if not success:
              print("\nâŒ All export methods failed. Inspecting API...")
              from yomitoku import DocumentAnalyzer
              analyzer = DocumentAnalyzer(configs={"device": "cpu"})
              print("\nAvailable analyzer attributes:")
              for attr in dir(analyzer):
                  if not attr.startswith('_'):
                      print(f"  - {attr}")
              if hasattr(analyzer, 'text_detector'):
                  print("\ntext_detector attributes:")
                  for attr in dir(analyzer.text_detector):
                      if 'export' in attr.lower() or 'onnx' in attr.lower():
                          print(f"  - {attr}")
              sys.exit(1)

          # Verify file sizes
          detector_size = os.path.getsize("./models/text_detector.onnx")
          recognizer_size = os.path.getsize("./models/text_recognizer.onnx")

          print(f"\nâœ… Detector: {detector_size / 1024 / 1024:.2f} MB")
          print(f"âœ… Recognizer: {recognizer_size / 1024 / 1024:.2f} MB")
          print("âœ… All models exported successfully!")
          EOF

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: '.'

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
